{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ps-renlab2/sunan/anaconda3/envs/enformer_pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from enformer_pytorch import Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7227, 0.5711, 0.6251,  ..., 0.6369, 0.7891, 0.6241],\n",
       "         [0.6697, 0.5736, 0.6709,  ..., 0.6348, 0.7374, 0.6948],\n",
       "         [0.5989, 0.6619, 0.8082,  ..., 0.7603, 0.6847, 0.7742],\n",
       "         ...,\n",
       "         [0.6839, 0.6627, 0.7101,  ..., 0.6694, 0.7648, 0.6375],\n",
       "         [0.6704, 0.5838, 0.7504,  ..., 0.6395, 0.7257, 0.6479],\n",
       "         [0.6304, 0.6314, 0.6335,  ..., 0.7391, 0.7876, 0.8259]]],\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Enformer.from_hparams(\n",
    "    dim = 1536,\n",
    "    depth = 11,\n",
    "    heads = 8,\n",
    "    output_heads = dict(human = 5313, mouse = 1643),\n",
    "    target_length = 896,\n",
    ")\n",
    "    \n",
    "seq = torch.randint(0, 5, (1, 196_608)) # for ACGTN, in that order (-1 for padding)\n",
    "output = model(seq)\n",
    "\n",
    "output['human'] # (1, 896, 5313)\n",
    "output['mouse'] # (1, 896, 1643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6487, 0.7115, 0.6171,  ..., 0.6917, 0.7177, 0.7240],\n",
       "         [0.5758, 0.7815, 0.6534,  ..., 0.8020, 0.8190, 0.7712],\n",
       "         [0.6355, 0.6589, 0.6536,  ..., 0.6495, 0.7747, 0.8103],\n",
       "         ...,\n",
       "         [0.6162, 0.7984, 0.7043,  ..., 0.6981, 0.6390, 0.7565],\n",
       "         [0.5688, 0.8153, 0.7222,  ..., 0.6674, 0.7446, 0.7474],\n",
       "         [0.6562, 0.7683, 0.6175,  ..., 0.7304, 0.6856, 0.7335]]],\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enformer_pytorch import Enformer, seq_indices_to_one_hot\n",
    "model = Enformer.from_hparams(\n",
    "    dim = 1536,\n",
    "    depth = 11,\n",
    "    heads = 8,\n",
    "    output_heads = dict(human = 5313, mouse = 1643),\n",
    "    target_length = 896,\n",
    ")\n",
    "\n",
    "seq = torch.randint(0, 5, (1, 196_608))\n",
    "one_hot = seq_indices_to_one_hot(seq)\n",
    "\n",
    "output = model(one_hot)\n",
    "\n",
    "output['human'] # (1, 896, 5313)\n",
    "output['mouse'] # (1, 896, 1643)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1624, -0.0074, -0.1611,  ...,  0.0215, -0.1547,  0.1957],\n",
       "         [-0.0485,  0.7589, -0.1491,  ..., -0.0914,  0.2149, -0.0246],\n",
       "         [-0.0544, -0.1033, -0.1592,  ...,  0.0000,  0.1360,  0.2412],\n",
       "         ...,\n",
       "         [-0.1632,  0.1100, -0.1588,  ...,  0.3035,  0.0000, -0.0145],\n",
       "         [-0.1434, -0.0886, -0.1269,  ..., -0.1216,  0.1450, -0.0230],\n",
       "         [-0.0593,  0.4288, -0.1504,  ...,  0.2306, -0.0000,  0.0000]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from enformer_pytorch import Enformer, seq_indices_to_one_hot\n",
    "\n",
    "model = Enformer.from_hparams(\n",
    "    dim = 1536,\n",
    "    depth = 11,\n",
    "    heads = 8,\n",
    "    output_heads = dict(human = 5313, mouse = 1643),\n",
    "    target_length = 896,\n",
    ")\n",
    "\n",
    "seq = torch.randint(0, 5, (1, 196_608))\n",
    "one_hot = seq_indices_to_one_hot(seq)\n",
    "\n",
    "output, embeddings = model(one_hot, return_embeddings = True)\n",
    "\n",
    "embeddings # (1, 896, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from enformer_pytorch import Enformer, seq_indices_to_one_hot\n",
    "\n",
    "model = Enformer.from_hparams(\n",
    "    dim = 1536,\n",
    "    depth = 11,\n",
    "    heads = 8,\n",
    "    output_heads = dict(human = 5313, mouse = 1643),\n",
    "    target_length = 200,\n",
    ").cuda()\n",
    "\n",
    "seq = torch.randint(0, 5, (196_608 // 2,)).cuda()\n",
    "target = torch.randn(200, 5313).cuda()\n",
    "\n",
    "loss = model(\n",
    "    seq,\n",
    "    head = 'human',\n",
    "    target = target\n",
    ")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# after much training\n",
    "\n",
    "corr_coef = model(\n",
    "    seq,\n",
    "    head = 'human',\n",
    "    target = target,\n",
    "    return_corr_coef = True\n",
    ")\n",
    "\n",
    "corr_coef # pearson R, used as a metric in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2911\n",
      "Epoch 2, Loss: 0.0087\n",
      "Epoch 3, Loss: -0.0104\n",
      "Epoch 4, Loss: -0.0541\n",
      "Epoch 5, Loss: -0.1054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0055, 0.0075, 0.0065, 0.0064], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "model = Enformer.from_hparams(\n",
    "    dim = 1536,\n",
    "    depth = 11,\n",
    "    heads = 8,\n",
    "    output_heads = dict(human = 5313, mouse = 1643),\n",
    "    target_length = 200,\n",
    ").cuda()\n",
    "\n",
    "seq = torch.randint(0, 5, (196_608 // 2,)).cuda()\n",
    "target = torch.randn(200, 5313).cuda()\n",
    "\n",
    "loss = model(\n",
    "    seq,\n",
    "    head = 'human',\n",
    "    target = target\n",
    ")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# after much training\n",
    "num_epochs = 5\n",
    "train_seqs = torch.randint(0, 5, (100, 196_608 // 2))\n",
    "train_targets = torch.randn(100, 200, 5313)\n",
    "\n",
    "train_dataset = TensorDataset(train_seqs, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for seq, target in train_loader:\n",
    "        seq, target = seq.cuda(), target.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(seq, head=\"human\", target=target)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corr_coef = model(\n",
    "    seq,\n",
    "    head = 'human',\n",
    "    target = target,\n",
    "    return_corr_coef = True\n",
    ")\n",
    "\n",
    "corr_coef # pearson R, used as a metric in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ps-renlab2/sunan/anaconda3/envs/enformer_pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Step 10/13, Loss: 0.4358\n",
      "Epoch 1/5, Step 13/13, Loss: 0.2922\n",
      "Epoch 1 completed. Average Loss: 0.5321\n",
      "Epoch 2/5, Step 10/13, Loss: 0.0194\n",
      "Epoch 2/5, Step 13/13, Loss: 0.0103\n",
      "Epoch 2 completed. Average Loss: 0.0828\n",
      "Epoch 3/5, Step 10/13, Loss: 0.0027\n",
      "Epoch 3/5, Step 13/13, Loss: 0.0018\n",
      "Epoch 3 completed. Average Loss: 0.0023\n",
      "Epoch 4/5, Step 10/13, Loss: -0.0088\n",
      "Epoch 4/5, Step 13/13, Loss: -0.0252\n",
      "Epoch 4 completed. Average Loss: -0.0082\n",
      "Epoch 5/5, Step 10/13, Loss: -0.0288\n",
      "Epoch 5/5, Step 13/13, Loss: -0.0260\n",
      "Epoch 5 completed. Average Loss: -0.0290\n",
      "Pearson Correlation Coefficient: 0.0011403672397136688\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from enformer_pytorch import Enformer\n",
    "import torch\n",
    "\n",
    "# Define the model\n",
    "model = Enformer.from_hparams(\n",
    "    dim=1536,\n",
    "    depth=11,\n",
    "    heads=8,\n",
    "    output_heads=dict(human=5313, mouse=1643),\n",
    "    target_length=200,\n",
    ").cuda()\n",
    "\n",
    "# Training configurations\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "train_seqs = torch.randint(0, 5, (100, 196_608 // 2))  # 100 sequences\n",
    "train_targets = torch.randn(100, 200, 5313)  # corresponding targets\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = TensorDataset(train_seqs, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(train_loader)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for step, (seq, target) in enumerate(train_loader, start=1):\n",
    "        seq, target = seq.cuda(), target.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = model(seq, head=\"human\", target=target)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Log every 10 steps\n",
    "        if step % 10 == 0 or step == steps_per_epoch:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Step {step}/{steps_per_epoch}, \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    avg_loss = total_loss / steps_per_epoch\n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluate Pearson Correlation Coefficient\n",
    "seq = torch.randint(0, 5, (196_608 // 2,)).cuda()\n",
    "target = torch.randn(200, 5313).cuda()\n",
    "corr_coef = model(seq, head=\"human\", target=target, return_corr_coef=True)\n",
    "print(f\"Pearson Correlation Coefficient: {corr_coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enformer_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
